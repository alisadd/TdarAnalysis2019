{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to analyze all documents downloaded to TDar in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    '''function to get page content and transform it into bs object'''\n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.text, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make first page soup\n",
    "soup = make_soup(\"https://core.tdar.org/scholar/scholar?year=2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One page test\n",
    "box = soup.find(\"a\", class_=\"resourceLink\")\n",
    "link = \"https://core.tdar.org/\"+box[\"href\"]\n",
    "project_html = requests.get(link)\n",
    "project_soup = bs(project_html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(keyword_type):\n",
    "    '''function to get keywords from the page\n",
    "    input: keyword type\n",
    "    output: contents of the list of names'''\n",
    "    keywords = []\n",
    "    #find correct paragraph\n",
    "    for paragraph in project_soup.find_all(\"p\", class_=\"break-word\"):\n",
    "        if paragraph.find(\"strong\").text == keyword_type:\n",
    "            box = paragraph\n",
    "    #display categories text\n",
    "            for item in box.find_all(\"a\", href=True):\n",
    "                keywords.append(item.text.strip())\n",
    "            break\n",
    "    return \", \".join(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sidebarInfo(tag):\n",
    "    '''function to get information from the sidebar\n",
    "    input: sidebar tag name\n",
    "    output: tag content'''\n",
    "    sidebar = project_soup.find(\"div\", {\"id\": \"sidebar-right\"})\n",
    "    br_tag = sidebar.find(\"strong\", text=tag).nextSibling\n",
    "    sidebarInfo = br_tag.nextSibling\n",
    "    return sidebarInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the csv document and name columns\n",
    "tdar_data = open(\"TdarData.csv\", \"w\")\n",
    "csv_writer = csv.writer(tdar_data)\n",
    "csv_writer.writerow([\"Title\", \"URL\", \"Year\", \"Investigation Type\", \"Geographic Keywords\", \"Culture\", \"Language\"])\n",
    "# Extract page links\n",
    "for title in soup.find_all(\"a\", class_=\"resourceLink\"):\n",
    "    title_links = \"https://core.tdar.org/\"+title[\"href\"]\n",
    "    # Get project titles\n",
    "    title_text = title.text\n",
    "    # Get year of the project from title\n",
    "    year_pattern = re.compile(\"(\\d{4}\\)$)\")\n",
    "    try:\n",
    "        year_find = re.search(year_pattern, title_text)\n",
    "        year_result = year_find.group()[:-1]\n",
    "    except AttributeError:\n",
    "        year_result = None\n",
    "    project_soup = make_soup(title_links)\n",
    "    try:\n",
    "        inv_type = get_keywords(\"Investigation Types  \")\n",
    "    except AttributeError:\n",
    "        inv_type = None\n",
    "    try:\n",
    "        geography = get_keywords(\"Geographic Keywords  \")\n",
    "    except AttributeError:\n",
    "        geography = None\n",
    "    try:\n",
    "        culture = get_keywords(\"Culture  \")\n",
    "    except AttributeError:\n",
    "        culture = None\n",
    "    try:\n",
    "        language = get_sidebarInfo(\"Language\")\n",
    "    except AttributeError:\n",
    "        language = None\n",
    "    # Write data into the document\n",
    "    csv_writer.writerow([title_text, title_links, year_result, inv_type, geography, culture, language])\n",
    "#close document\n",
    "tdar_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
